{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnosis using logistic regression: Wisconsin Breast Cancer Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean radius',\n",
       " 'mean texture',\n",
       " 'mean perimeter',\n",
       " 'mean area',\n",
       " 'mean smoothness',\n",
       " 'mean compactness',\n",
       " 'mean concavity',\n",
       " 'mean concave points',\n",
       " 'mean symmetry',\n",
       " 'mean fractal dimension',\n",
       " 'radius error',\n",
       " 'texture error',\n",
       " 'perimeter error',\n",
       " 'area error',\n",
       " 'smoothness error',\n",
       " 'compactness error',\n",
       " 'concavity error',\n",
       " 'concave points error',\n",
       " 'symmetry error',\n",
       " 'fractal dimension error',\n",
       " 'worst radius',\n",
       " 'worst texture',\n",
       " 'worst perimeter',\n",
       " 'worst area',\n",
       " 'worst smoothness',\n",
       " 'worst compactness',\n",
       " 'worst concavity',\n",
       " 'worst concave points',\n",
       " 'worst symmetry',\n",
       " 'worst fractal dimension']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malignant', 'benign']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the splits (train and test/dev)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the data\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the logistic regression model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train it using training set\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the prediction on test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "p1 = y_pred_prob[:,0]\n",
    "p2 = y_pred_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Class</th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Pr(Perk=0|X)</th>\n",
       "      <th>Pr(Perk=1|X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178281</td>\n",
       "      <td>0.821719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967486</td>\n",
       "      <td>0.032514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.836449</td>\n",
       "      <td>0.163551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058157</td>\n",
       "      <td>0.941843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.980258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703815</td>\n",
       "      <td>0.296185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484224</td>\n",
       "      <td>0.515776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040614</td>\n",
       "      <td>0.959386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.128546</td>\n",
       "      <td>0.871454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740280</td>\n",
       "      <td>0.259720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.917299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667636</td>\n",
       "      <td>0.332364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>0.958574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979584</td>\n",
       "      <td>0.020416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053190</td>\n",
       "      <td>0.946810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.993067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.998573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994541</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275054</td>\n",
       "      <td>0.724946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.923333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.991592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>0.963838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.946625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050779</td>\n",
       "      <td>0.949221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072525</td>\n",
       "      <td>0.927475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063284</td>\n",
       "      <td>0.936716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991541</td>\n",
       "      <td>0.008459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826770</td>\n",
       "      <td>0.173230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950227</td>\n",
       "      <td>0.049773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980421</td>\n",
       "      <td>0.019579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.968569</td>\n",
       "      <td>0.031431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049594</td>\n",
       "      <td>0.950406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077480</td>\n",
       "      <td>0.922520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065337</td>\n",
       "      <td>0.934663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336136</td>\n",
       "      <td>0.663864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191360</td>\n",
       "      <td>0.808640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.982860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020924</td>\n",
       "      <td>0.979076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.988299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990748</td>\n",
       "      <td>0.009252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989002</td>\n",
       "      <td>0.010998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.989960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942286</td>\n",
       "      <td>0.057714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825247</td>\n",
       "      <td>0.174753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.998100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977725</td>\n",
       "      <td>0.022275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>0.051253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041866</td>\n",
       "      <td>0.958134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095945</td>\n",
       "      <td>0.904055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090626</td>\n",
       "      <td>0.909374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999089</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.290450</td>\n",
       "      <td>0.709550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134283</td>\n",
       "      <td>0.865717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794852</td>\n",
       "      <td>0.205148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.960191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.406871</td>\n",
       "      <td>0.593129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     True Class  Predicted Class  Pr(Perk=0|X)  Pr(Perk=1|X)\n",
       "0             1                1      0.178281      0.821719\n",
       "1             0                0      0.967486      0.032514\n",
       "2             0                0      0.836449      0.163551\n",
       "3             1                1      0.058157      0.941843\n",
       "4             1                1      0.019742      0.980258\n",
       "5             0                0      0.999935      0.000065\n",
       "6             0                0      0.999303      0.000697\n",
       "7             0                0      0.703815      0.296185\n",
       "8             1                1      0.484224      0.515776\n",
       "9             1                1      0.040614      0.959386\n",
       "10            1                1      0.128546      0.871454\n",
       "11            0                0      0.740280      0.259720\n",
       "12            1                1      0.082701      0.917299\n",
       "13            0                0      0.667636      0.332364\n",
       "14            1                1      0.041426      0.958574\n",
       "15            0                0      0.979584      0.020416\n",
       "16            1                1      0.053190      0.946810\n",
       "17            1                1      0.006933      0.993067\n",
       "18            1                1      0.001427      0.998573\n",
       "19            0                0      0.994541      0.005459\n",
       "20            0                1      0.275054      0.724946\n",
       "21            1                1      0.076667      0.923333\n",
       "22            0                0      0.999537      0.000463\n",
       "23            1                1      0.008408      0.991592\n",
       "24            1                1      0.036162      0.963838\n",
       "25            1                1      0.053375      0.946625\n",
       "26            1                1      0.050779      0.949221\n",
       "27            1                1      0.072525      0.927475\n",
       "28            1                1      0.063284      0.936716\n",
       "29            0                0      0.991541      0.008459\n",
       "..          ...              ...           ...           ...\n",
       "84            0                0      0.826770      0.173230\n",
       "85            0                0      0.950227      0.049773\n",
       "86            0                0      0.980421      0.019579\n",
       "87            0                0      0.968569      0.031431\n",
       "88            1                1      0.049594      0.950406\n",
       "89            1                1      0.077480      0.922520\n",
       "90            1                1      0.065337      0.934663\n",
       "91            1                1      0.336136      0.663864\n",
       "92            1                1      0.191360      0.808640\n",
       "93            1                1      0.017140      0.982860\n",
       "94            1                1      0.020924      0.979076\n",
       "95            1                1      0.011701      0.988299\n",
       "96            0                0      0.990748      0.009252\n",
       "97            0                0      0.989002      0.010998\n",
       "98            1                1      0.010040      0.989960\n",
       "99            0                0      0.942286      0.057714\n",
       "100           0                0      0.825247      0.174753\n",
       "101           1                1      0.001900      0.998100\n",
       "102           0                0      0.977725      0.022275\n",
       "103           0                0      0.948747      0.051253\n",
       "104           1                1      0.041866      0.958134\n",
       "105           1                1      0.095945      0.904055\n",
       "106           1                1      0.090626      0.909374\n",
       "107           0                0      0.999089      0.000911\n",
       "108           1                1      0.290450      0.709550\n",
       "109           1                1      0.134283      0.865717\n",
       "110           0                0      0.794852      0.205148\n",
       "111           1                1      0.039809      0.960191\n",
       "112           1                1      0.406871      0.593129\n",
       "113           0                0      0.999753      0.000247\n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'True Class': y_test, \n",
    "                   'Predicted Class': y_pred, \n",
    "                   'Pr(Perk=0|X)': p1,\n",
    "                   'Pr(Perk=1|X)': p2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "#test performance of the model\n",
    "print('Test Accuracy:',np.mean(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f44f053be80>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
